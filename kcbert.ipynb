{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOs5HLLsS2rNhmB02NApdOu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qFa6UN7qgGi6","executionInfo":{"status":"ok","timestamp":1704607889083,"user_tz":-540,"elapsed":5376,"user":{"displayName":"dg l","userId":"00786945182033196125"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n","        input_ids = encoding['input_ids'].squeeze()\n","        attention_mask = encoding['attention_mask'].squeeze()\n","\n","        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"]},{"cell_type":"code","source":["# 16개 레이블링 돌릴 때만\n","def check_label(label):\n","  if label['label'] == 'intp':\n","    return 0\n","  elif label['label'] == 'intj':\n","    return 1\n","  elif label['label'] == 'infp':\n","    return 2\n","  elif label['label'] == 'infj':\n","    return 3\n","  elif label['label'] == 'istp':\n","    return 4\n","  elif label['label'] == 'istj':\n","    return 5\n","  elif label['label'] == 'isfp':\n","    return 6\n","  elif label['label'] == 'isfj':\n","    return 7\n","  elif label['label'] == 'entp':\n","    return 8\n","  elif label['label'] == 'entj':\n","    return 9\n","  elif label['label'] == 'enfp':\n","    return 10\n","  elif label['label'] == 'enfj':\n","    return 11\n","  elif label['label'] == 'estp':\n","    return 12\n","  elif label['label'] == 'estj':\n","    return 13\n","  elif label['label'] == 'esfp':\n","    return 14\n","  elif label['label'] == 'esfj':\n","    return 15"],"metadata":{"id":"EZ6YIspX_Fxc","executionInfo":{"status":"ok","timestamp":1704612427062,"user_tz":-540,"elapsed":3556,"user":{"displayName":"dg l","userId":"00786945182033196125"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["rawdata = pd.read_csv('mbti-train.tsv', sep='\\t') # 데이터 셋에 따라 수정. 데이터셋은 tsv 파일에 document와 label이 tab으로 구분되어 있어야 함.\n","\n","texts = []\n","labels = []\n","\n","for idx, label in rawdata.iterrows():\n","  texts.append(label['document'])\n","  #labels.append(check_label(label))\n","  labels.append(label['label'])"],"metadata":{"id":"nTM3el1HEUlx","executionInfo":{"status":"ok","timestamp":1704631228386,"user_tz":-540,"elapsed":2731,"user":{"displayName":"dg l","userId":"00786945182033196125"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["model_name = \"beomi/kcbert-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=16) # 라벨링 종류 수에 따라 수정\n","\n","max_length = 128\n","\n","labels = torch.tensor(labels, dtype=torch.long)\n","dataset = CustomDataset(texts, labels, tokenizer, max_length)\n","\n","batch_size = 64\n","\n","from sklearn.model_selection import train_test_split\n","train, test = train_test_split(dataset, test_size=0.15, random_state=42)\n","\n","train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4TNpT0Xyx2O","executionInfo":{"status":"ok","timestamp":1704631254148,"user_tz":-540,"elapsed":25766,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"4112465f-a92a-4d13-ef88-54d39a92f9b2"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if device.type == 'cuda':\n","    print(\"Current device:\", torch.cuda.get_device_name(device))\n","else:\n","    print(\"Current device: CPU\")\n","model = model.to(device)\n","\n","learning_rate = 1e-5\n","epochs = 5\n","\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfGX4XPoG-gA","executionInfo":{"status":"ok","timestamp":1704631254148,"user_tz":-540,"elapsed":22,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"d9e303d4-7130-4495-a21c-0652c04ca8bd"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Current device: Tesla T4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# 16개 레이블에 대해 돌림\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 모델에 입력을 주어 예측을 생성합니다.\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n","        logits = outputs.logits\n","        # 손실을 계산합니다.\n","        loss = criterion(logits, labels)\n","        # 역전파를 통해 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저를 사용해 가중치를 업데이트\n","        optimizer.step()\n","        # 에포크 전체 손실을 누적합니다.\n","        total_loss += loss.item()\n","\n","    # 에포크 평균 손실 계산\n","    avg_loss = total_loss / len(train_dataloader)\n","    # 에포크별 손실 출력\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    val_total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_batch in valid_dataloader:\n","            # Validation 데이터 가져오기\n","            val_input_ids = val_batch['input_ids']\n","            val_attention_mask = val_batch['attention_mask']\n","            val_labels = val_batch['label']\n","\n","            val_input_ids = val_input_ids.to(device)\n","            val_attention_mask = val_attention_mask.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            # 모델 예측\n","            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n","            val_logits = val_outputs.logits\n","\n","            # 손실 계산\n","            val_loss = criterion(val_logits, val_labels)\n","            val_total_loss += val_loss.item()\n","\n","            # 정확도 계산\n","            val_preds = val_logits.argmax(dim=1)\n","            correct += (val_preds == val_labels).sum().item()\n","            total += val_labels.size(0)\n","\n","    val_avg_loss = val_total_loss / len(valid_dataloader)\n","    val_accuracy = correct / total\n","    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJCBLadR_Omw","executionInfo":{"status":"ok","timestamp":1704617137115,"user_tz":-540,"elapsed":4551731,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"dcad504a-5d33-48db-822e-3b7e1ee64849"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg Loss: 2.5421\n","Validation Loss: 2.4552 - Validation Accuracy: 0.2154\n","Epoch 2/5 - Avg Loss: 2.4017\n","Validation Loss: 2.4289 - Validation Accuracy: 0.2284\n","Epoch 3/5 - Avg Loss: 2.3003\n","Validation Loss: 2.4332 - Validation Accuracy: 0.2274\n","Epoch 4/5 - Avg Loss: 2.1560\n","Validation Loss: 2.5011 - Validation Accuracy: 0.2230\n","Epoch 5/5 - Avg Loss: 1.9571\n","Validation Loss: 2.5957 - Validation Accuracy: 0.2219\n"]}]},{"cell_type":"code","source":["# ie에 대해 레이블링 후 돌림\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 모델에 입력을 주어 예측을 생성합니다.\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n","        logits = outputs.logits\n","        # 손실을 계산합니다.\n","        loss = criterion(logits, labels)\n","        # 역전파를 통해 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저를 사용해 가중치를 업데이트\n","        optimizer.step()\n","        # 에포크 전체 손실을 누적합니다.\n","        total_loss += loss.item()\n","\n","    # 에포크 평균 손실 계산\n","    avg_loss = total_loss / len(train_dataloader)\n","    # 에포크별 손실 출력\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    val_total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_batch in valid_dataloader:\n","            # Validation 데이터 가져오기\n","            val_input_ids = val_batch['input_ids']\n","            val_attention_mask = val_batch['attention_mask']\n","            val_labels = val_batch['label']\n","\n","            val_input_ids = val_input_ids.to(device)\n","            val_attention_mask = val_attention_mask.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            # 모델 예측\n","            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n","            val_logits = val_outputs.logits\n","\n","            # 손실 계산\n","            val_loss = criterion(val_logits, val_labels)\n","            val_total_loss += val_loss.item()\n","\n","            # 정확도 계산\n","            val_preds = val_logits.argmax(dim=1)\n","            correct += (val_preds == val_labels).sum().item()\n","            total += val_labels.size(0)\n","\n","    val_avg_loss = val_total_loss / len(valid_dataloader)\n","    val_accuracy = correct / total\n","    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArocCVcbFzuf","executionInfo":{"status":"ok","timestamp":1704621917626,"user_tz":-540,"elapsed":4563210,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"33ff4ed9-83c7-4412-d0af-9e97921370ec"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg Loss: 0.6495\n","Validation Loss: 0.6451 - Validation Accuracy: 0.6401\n","Epoch 2/5 - Avg Loss: 0.6228\n","Validation Loss: 0.6583 - Validation Accuracy: 0.6387\n","Epoch 3/5 - Avg Loss: 0.5728\n","Validation Loss: 0.6742 - Validation Accuracy: 0.6197\n","Epoch 4/5 - Avg Loss: 0.4664\n","Validation Loss: 0.7734 - Validation Accuracy: 0.6210\n","Epoch 5/5 - Avg Loss: 0.3223\n","Validation Loss: 0.9638 - Validation Accuracy: 0.6081\n"]}]},{"cell_type":"code","source":["# ns에 대해 레이블링\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 모델에 입력을 주어 예측을 생성합니다.\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n","        logits = outputs.logits\n","        # 손실을 계산합니다.\n","        loss = criterion(logits, labels)\n","        # 역전파를 통해 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저를 사용해 가중치를 업데이트\n","        optimizer.step()\n","        # 에포크 전체 손실을 누적합니다.\n","        total_loss += loss.item()\n","\n","    # 에포크 평균 손실 계산\n","    avg_loss = total_loss / len(train_dataloader)\n","    # 에포크별 손실 출력\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    val_total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_batch in valid_dataloader:\n","            # Validation 데이터 가져오기\n","            val_input_ids = val_batch['input_ids']\n","            val_attention_mask = val_batch['attention_mask']\n","            val_labels = val_batch['label']\n","\n","            val_input_ids = val_input_ids.to(device)\n","            val_attention_mask = val_attention_mask.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            # 모델 예측\n","            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n","            val_logits = val_outputs.logits\n","\n","            # 손실 계산\n","            val_loss = criterion(val_logits, val_labels)\n","            val_total_loss += val_loss.item()\n","\n","            # 정확도 계산\n","            val_preds = val_logits.argmax(dim=1)\n","            correct += (val_preds == val_labels).sum().item()\n","            total += val_labels.size(0)\n","\n","    val_avg_loss = val_total_loss / len(valid_dataloader)\n","    val_accuracy = correct / total\n","    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2tLI64uYzC_","executionInfo":{"status":"ok","timestamp":1704626591809,"user_tz":-540,"elapsed":4598992,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"45c9e804-8f41-4d44-fadb-70444ebd6441"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg Loss: 0.5881\n","Validation Loss: 0.5782 - Validation Accuracy: 0.7082\n","Epoch 2/5 - Avg Loss: 0.5550\n","Validation Loss: 0.5803 - Validation Accuracy: 0.7113\n","Epoch 3/5 - Avg Loss: 0.5028\n","Validation Loss: 0.6000 - Validation Accuracy: 0.6939\n","Epoch 4/5 - Avg Loss: 0.3970\n","Validation Loss: 0.6770 - Validation Accuracy: 0.6790\n","Epoch 5/5 - Avg Loss: 0.2654\n","Validation Loss: 0.8748 - Validation Accuracy: 0.6700\n"]}]},{"cell_type":"code","source":["# tf에 대해 레이블링\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 모델에 입력을 주어 예측을 생성합니다.\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n","        logits = outputs.logits\n","        # 손실을 계산합니다.\n","        loss = criterion(logits, labels)\n","        # 역전파를 통해 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저를 사용해 가중치를 업데이트\n","        optimizer.step()\n","        # 에포크 전체 손실을 누적합니다.\n","        total_loss += loss.item()\n","\n","    # 에포크 평균 손실 계산\n","    avg_loss = total_loss / len(train_dataloader)\n","    # 에포크별 손실 출력\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    val_total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_batch in valid_dataloader:\n","            # Validation 데이터 가져오기\n","            val_input_ids = val_batch['input_ids']\n","            val_attention_mask = val_batch['attention_mask']\n","            val_labels = val_batch['label']\n","\n","            val_input_ids = val_input_ids.to(device)\n","            val_attention_mask = val_attention_mask.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            # 모델 예측\n","            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n","            val_logits = val_outputs.logits\n","\n","            # 손실 계산\n","            val_loss = criterion(val_logits, val_labels)\n","            val_total_loss += val_loss.item()\n","\n","            # 정확도 계산\n","            val_preds = val_logits.argmax(dim=1)\n","            correct += (val_preds == val_labels).sum().item()\n","            total += val_labels.size(0)\n","\n","    val_avg_loss = val_total_loss / len(valid_dataloader)\n","    val_accuracy = correct / total\n","    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0E67JvCcqhOn","executionInfo":{"status":"ok","timestamp":1704631225659,"user_tz":-540,"elapsed":4578025,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"9c486c9d-0fc4-465e-9947-a1bb8e5157f3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg Loss: 0.6632\n","Validation Loss: 0.6434 - Validation Accuracy: 0.6276\n","Epoch 2/5 - Avg Loss: 0.6290\n","Validation Loss: 0.6583 - Validation Accuracy: 0.6150\n","Epoch 3/5 - Avg Loss: 0.5805\n","Validation Loss: 0.6690 - Validation Accuracy: 0.6182\n","Epoch 4/5 - Avg Loss: 0.4786\n","Validation Loss: 0.7417 - Validation Accuracy: 0.6135\n","Epoch 5/5 - Avg Loss: 0.3314\n","Validation Loss: 0.9344 - Validation Accuracy: 0.5946\n"]}]},{"cell_type":"code","source":["#pj에 대해 레이블링\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['label']\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        # 모델에 입력을 주어 예측을 생성합니다.\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # 모델 출력에서 로짓(분류에 대한 점수)을 얻습니다.\n","        logits = outputs.logits\n","        # 손실을 계산합니다.\n","        loss = criterion(logits, labels)\n","        # 역전파를 통해 그래디언트 계산\n","        loss.backward()\n","        # 옵티마이저를 사용해 가중치를 업데이트\n","        optimizer.step()\n","        # 에포크 전체 손실을 누적합니다.\n","        total_loss += loss.item()\n","\n","    # 에포크 평균 손실 계산\n","    avg_loss = total_loss / len(train_dataloader)\n","    # 에포크별 손실 출력\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    val_total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_batch in valid_dataloader:\n","            # Validation 데이터 가져오기\n","            val_input_ids = val_batch['input_ids']\n","            val_attention_mask = val_batch['attention_mask']\n","            val_labels = val_batch['label']\n","\n","            val_input_ids = val_input_ids.to(device)\n","            val_attention_mask = val_attention_mask.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            # 모델 예측\n","            val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n","            val_logits = val_outputs.logits\n","\n","            # 손실 계산\n","            val_loss = criterion(val_logits, val_labels)\n","            val_total_loss += val_loss.item()\n","\n","            # 정확도 계산\n","            val_preds = val_logits.argmax(dim=1)\n","            correct += (val_preds == val_labels).sum().item()\n","            total += val_labels.size(0)\n","\n","    val_avg_loss = val_total_loss / len(valid_dataloader)\n","    val_accuracy = correct / total\n","    print(f\"Validation Loss: {val_avg_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y6V5fuN4qh1a","executionInfo":{"status":"ok","timestamp":1704635837461,"user_tz":-540,"elapsed":4583330,"user":{"displayName":"dg l","userId":"00786945182033196125"}},"outputId":"7b5e3b6e-f3a6-4ee5-f37a-42d2a028a5b0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5 - Avg Loss: 0.6510\n","Validation Loss: 0.6466 - Validation Accuracy: 0.6380\n","Epoch 2/5 - Avg Loss: 0.6273\n","Validation Loss: 0.6407 - Validation Accuracy: 0.6245\n","Epoch 3/5 - Avg Loss: 0.5882\n","Validation Loss: 0.6694 - Validation Accuracy: 0.6145\n","Epoch 4/5 - Avg Loss: 0.5033\n","Validation Loss: 0.7381 - Validation Accuracy: 0.6076\n","Epoch 5/5 - Avg Loss: 0.3702\n","Validation Loss: 0.8993 - Validation Accuracy: 0.5749\n"]}]}]}